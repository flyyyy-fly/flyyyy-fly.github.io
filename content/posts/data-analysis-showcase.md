---
title: "é¡¹ç›®æ•°æ®é›†éƒ¨åˆ†å±•ç¤º"
date: 2026-02-05
draft: false
---

### æ•°æ®é›†è¯´æ˜
Â·ç®€è¦è¯´æ˜ï¼šæ•°æ®ç”¨äºä¸Šå¸‚å…¬å¸èèµ„èåˆ¸ä¸èµ„æœ¬ç»“æ„è°ƒæ•´é€Ÿåº¦ç ”ç©¶ï¼Œä»£ç å±•ç¤ºäº†å®Œæ•´æ•°æ®æ¸…æ´—ä¸åˆ†ææµç¨‹

Â·æ•°æ®æ¥æºï¼šCSMARæ•°æ®åº“ã€Windæ•°æ®åº“

Â·æ—¶é—´èŒƒå›´ï¼š2006-2021å¹´

### ğŸ“Š æ•°æ®é›†é¢„è§ˆ (Top 5 Rows)

ä¸ºäº†ä¿æŠ¤éšç§/å‡å°‘ç¯‡å¹…ï¼Œè¿™é‡Œä»…å±•ç¤ºæ•°æ®é›†çš„æ ¸å¿ƒæ ·æœ¬ã€‚å®Œæ•´çš„åˆ†æé€»è¾‘è¯·å‚è€ƒä¸‹æ–¹ä»£ç ã€‚
| è¯åˆ¸ä»£ç  | è¯åˆ¸ç®€ç§° | ç»Ÿè®¡æˆªæ­¢æ—¥æœŸ | æŠ¥è¡¨ç±»å‹ | å›ºå®šèµ„äº§å‡€é¢ | èµ„äº§æ€»è®¡ | è´Ÿå€ºåˆè®¡ | æ¯ç¨å‰åˆ©æ¶¦ï¼ˆEBITï¼‰ | è¥ä¸šæ”¶å…¥ | ç¬¬ä¸€å¤§è‚¡ä¸œæŒè‚¡æ¯”ç‡(%) | ç‹¬ç«‹è‘£äº‹å æ¯” | å¹´ä»½ | å®é™…è´Ÿå€ºç‡ | ä¼ä¸šè§„æ¨¡ | ç›ˆåˆ©èƒ½åŠ› | HHI(A) | è¡Œä¸šç«äº‰åˆ†ç»„ | Treat | Post | DID |
|---------|-----------|-------------|---------|-------------|---------|---------|-------------------|---------|----------------------|-------------|-----|-----------|---------|---------|--------|-------------|-------|------|-----|
| 000002 | ä¸‡ç§‘A | 2021 | A | 12821059775.0 | 1938638128699.08 | 1545865352173.99 | 56606455057.0 | 452797773974.14 | 27.89 | 36.36 | 2021 | 0.797397579924491 | 28.2930068469736 | 0.0291990827058919 | 0.102239 | ä½ç«äº‰ç»„ | 1 | 1 | 1 |
| 000002 | ä¸‡ç§‘A | 2020 | A | 12577342742.0 | 1869177094005.55 | 1519332620662.33 | 84820855660.0 | 419111677714.12 | 27.91 | 36.36 | 2020 | 0.812835030738836 | 28.2565193932602 | 0.045378715548987 | 0.116743 | ä½ç«äº‰ç»„ | 1 | 1 | 1 |
| 000002 | ä¸‡ç§‘A | 2019 | A | 12399838267.0 | 1729929450401.23 | 1459350334988.27 | 82275231229.0 | 367893877538.94 | 28.69 | 40.0 | 2019 | 0.843589508606722 | 28.1791017434918 | 0.047559876623921 | 0.103484 | ä½ç«äº‰ç»„ | 1 | 1 | 1 |
| 000002 | ä¸‡ç§‘A | 2018 | A | 11533798650.0 | 1528579356474.81 | 1292958626477.23 | 73458776044.0 | 297679331103.19 | 29.38 | 36.36 | 2018 | 0.845856396660383 | 28.0553598948065 | 0.0480568939600425 | 0.095733 | é«˜ç«äº‰ç»„ | 1 | 1 | 1 |
| 000002 | ä¸‡ç§‘A | 2017 | A | 7098808083.0 | 1165346917804.55 | 978672978646.26 | 53217209447.0 | 242897110250.52 | 29.38 | 36.36 | 2017 | 0.839812560271774 | 27.7840399421407 | 0.0456664094044616 | 0.101849 | é«˜ç«äº‰ç»„ | 1 | 1 | 1 |

> **è¯´æ˜**ï¼šåŸå§‹æ•°æ®é›†åŒ…å« 10,000+ æ¡è®°å½•ï¼Œä»¥ä¸Šä»…ä¸ºç»“æ„å±•ç¤ºã€‚

---

### ğŸ å¤„ç†æ­¤æ•°æ®çš„ Python ä»£ç 

```python

import pandas as pd
import numpy as np

# ====================== å…¨å±€é…ç½® ======================
INPUT_PATH = "./"
OUTPUT_PATH = "./"
ENCODING = "utf-8-sig"

# ====================== å·¥å…·å‡½æ•° ======================
def linear_regression(X, y):
    """æ‰‹åŠ¨å®ç°çº¿æ€§å›å½’ï¼Œé¿å…ä¾èµ–ç¬¬ä¸‰æ–¹ç»Ÿè®¡åº“"""
    X = np.column_stack([np.ones(len(X)), X])
    beta = np.linalg.inv(X.T @ X) @ X.T @ y
    return beta

# ====================== æ­¥éª¤1ï¼šåˆå¹¶åŸå§‹è´¢åŠ¡ä¸äº¤æ˜“æ•°æ® ======================
print("="*60)
print("æ­¥éª¤1ï¼šåˆå¹¶åŸå§‹è´¢åŠ¡æ•°æ®ä¸äº¤æ˜“æ•°æ®")
print("="*60)

# è¯»å–FSå’ŒBFåˆå¹¶æ–‡ä»¶
df_fs_bf = pd.read_excel(f"{INPUT_PATH}åˆå¹¶_FS_BF.xlsx", engine="openpyxl")
print(f"FS_BFæ•°æ®é‡: {df_fs_bf.shape}")

# è¯»å–äº¤æ˜“æ•°æ®
df_trd = pd.read_excel(f"{INPUT_PATH}TRD_Co.xlsx", engine="openpyxl")
print(f"TRDæ•°æ®é‡: {df_trd.shape}")

# æŒ‰è¯åˆ¸ä»£ç å·¦è¿æ¥
merged_data_1 = pd.merge(df_fs_bf, df_trd, on="è¯åˆ¸ä»£ç ", how="left")
print(f"åˆå¹¶åmerged_data_1æ•°æ®é‡: {merged_data_1.shape}")

# ====================== æ­¥éª¤2ï¼šåˆå¹¶å…¬å¸æ²»ç†æ•°æ® ======================
print("\n" + "="*60)
print("æ­¥éª¤2ï¼šåˆå¹¶å…¬å¸æ²»ç†æ•°æ®")
print("="*60)

df_chn = pd.read_excel(f"{INPUT_PATH}CHN_Stkmt_ydetails(Merge Query).xlsx", engine="openpyxl")
print(f"CHNæ•°æ®é‡: {df_chn.shape}")

# æŒ‰è¯åˆ¸ä»£ç å’Œç»Ÿè®¡æˆªæ­¢æ—¥æœŸå·¦è¿æ¥
merged_data_2 = pd.merge(merged_data_1, df_chn, on=["è¯åˆ¸ä»£ç ", "ç»Ÿè®¡æˆªæ­¢æ—¥æœŸ"], how="left")
print(f"åˆå¹¶åmerged_data_2æ•°æ®é‡: {merged_data_2.shape}")

# ====================== æ­¥éª¤3ï¼šå¤„ç†HHIè¡Œä¸šé›†ä¸­åº¦æ•°æ® ======================
print("\n" + "="*60)
print("æ­¥éª¤3ï¼šå¤„ç†HHIè¡Œä¸šé›†ä¸­åº¦æ•°æ®")
print("="*60)

df_hhi = pd.read_excel(f"{INPUT_PATH}INDFI_HHI.xlsx", engine="openpyxl")
print(f"åŸå§‹HHIæ•°æ®é‡: {df_hhi.shape}")

# ç­›é€‰æ¡ä»¶
df_hhi = df_hhi[
    (df_hhi["å¸‚åœºç±»å‹"] == 21) &
    (df_hhi["æ˜¯å¦å‰”é™¤ ST æˆ– * ST è‚¡"] == 1) &
    (df_hhi["æ˜¯å¦å‰”é™¤å½“å¹´æ–°ä¸Šå¸‚ï¼Œå·²ç»é€€å¸‚æˆ–è¢«æš‚åœä¸Šå¸‚çš„å…¬å¸"] == 1)
]

# æå–å¹´ä»½
df_hhi["ç»Ÿè®¡æˆªæ­¢æ—¥æœŸ"] = pd.to_datetime(df_hhi["ç»Ÿè®¡æˆªæ­¢æ—¥æœŸ"])
df_hhi["å¹´ä»½"] = df_hhi["ç»Ÿè®¡æˆªæ­¢æ—¥æœŸ"].dt.year

# è¡Œä¸šä»£ç æ ¼å¼åŒ–ï¼šåˆ¶é€ ä¸šä¿ç•™ä¸¤ä½ï¼Œå…¶ä»–ä¿ç•™é¦–å­—æ¯
def format_industry_code(code):
    code = str(code).strip()
    if code.startswith("C"):
        return code[:2]
    return code[0]

df_hhi["è¡Œä¸šä»£ç "] = df_hhi["è¡Œä¸šä»£ç "].apply(format_industry_code)

# ä¿ç•™éœ€è¦çš„åˆ—
hhi_cleaned = df_hhi[["å¹´ä»½", "è¡Œä¸šä»£ç ", "HHI (A)"]].rename(columns={"HHI (A)": "HHI_A"})
hhi_cleaned.to_csv(f"{OUTPUT_PATH}hhi_cleaned.csv", encoding=ENCODING, index=False)
print(f"å¤„ç†åHHIæ•°æ®é‡: {hhi_cleaned.shape}")

# ====================== æ­¥éª¤4ï¼šæ¸…æ´—å…¬å¸è´¢åŠ¡æ•°æ® ======================
print("\n" + "="*60)
print("æ­¥éª¤4ï¼šæ¸…æ´—å…¬å¸è´¢åŠ¡æ•°æ®")
print("="*60)

# å‰”é™¤é‡‘èä¸š
df_clean = merged_data_2[merged_data_2["Indcd"] != "0001"].copy()

# åªä¿ç•™åˆå¹¶æŠ¥è¡¨
df_clean = df_clean[df_clean["æŠ¥è¡¨ç±»å‹"] == "A"]

# æå–å¹´ä»½
df_clean["ç»Ÿè®¡æˆªæ­¢æ—¥æœŸ"] = pd.to_datetime(df_clean["ç»Ÿè®¡æˆªæ­¢æ—¥æœŸ"])
df_clean["å¹´ä»½"] = df_clean["ç»Ÿè®¡æˆªæ­¢æ—¥æœŸ"].dt.year

# æ„å»ºè´¢åŠ¡æŒ‡æ ‡
df_clean["å®é™…è´Ÿå€ºç‡"] = df_clean["è´Ÿå€ºåˆè®¡"] / df_clean["èµ„äº§æ€»è®¡"]
df_clean["ä¼ä¸šè§„æ¨¡"] = np.log(df_clean["èµ„äº§æ€»è®¡"])
df_clean["ç›ˆåˆ©èƒ½åŠ›"] = df_clean["æ¯ç¨å‰åˆ©æ¶¦EBIT"] / df_clean["èµ„äº§æ€»è®¡"]
df_clean["æˆé•¿æ€§"] = df_clean["å¹´ä¸ªè‚¡æµé€šå¸‚å€¼"] / df_clean["èµ„äº§æ€»è®¡"]
df_clean["èµ„äº§æ‹…ä¿ä»·å€¼"] = df_clean["å›ºå®šèµ„äº§å‡€é¢"] / df_clean["èµ„äº§æ€»è®¡"]

# ä¿å­˜æ¸…æ´—åçš„å…¬å¸æ•°æ®
df_clean.to_excel(f"{OUTPUT_PATH}company_data_cleaned.xlsx", index=False, engine="openpyxl")
print(f"æ¸…æ´—åå…¬å¸æ•°æ®é‡: {df_clean.shape}")

# ====================== æ­¥éª¤5ï¼šåˆå¹¶æ•°æ®å¹¶æ„å»ºDIDæ¨¡å‹ ======================
print("\n" + "="*60)
print("æ­¥éª¤5ï¼šæ„å»ºDIDæ¨¡å‹ä¸è¡Œä¸šç«äº‰åˆ†ç»„")
print("="*60)

# åˆå¹¶è¡Œä¸šå¯¹ç…§è¡¨
df_industry_map = pd.read_csv(f"{INPUT_PATH}è¯åˆ¸è¡Œä¸šä»£ç å¯¹ç…§è¡¨.csv", encoding=ENCODING)
df_merged = pd.merge(df_clean, df_industry_map, on=["è¯åˆ¸ä»£ç ", "å¹´ä»½"], how="left")

# åˆå¹¶HHIæ•°æ®
df_merged = pd.merge(df_merged, hhi_cleaned, on=["å¹´ä»½", "è¡Œä¸šä»£ç "], how="left")

# å‰”é™¤HHIä¸ºç©ºçš„æ•°æ®
df_merged = df_merged.dropna(subset=["HHI_A"])

# æ„å»ºå®éªŒç»„æ ‡ç­¾Treat
df_merged["èèµ„èåˆ¸ä½™é¢"] = df_merged["èèµ„ä½™é¢(å…ƒ)"] + df_merged["èåˆ¸ä½™é¢(å…ƒ)"]
treat_list = df_merged[df_merged["èèµ„èåˆ¸ä½™é¢"] > 0]["è¯åˆ¸ä»£ç "].unique()
df_merged["Treat"] = df_merged["è¯åˆ¸ä»£ç "].isin(treat_list).astype(int)

# æ„å»ºæ”¿ç­–æ‰§è¡Œæ ‡ç­¾Post
first_year = df_merged[df_merged["èèµ„èåˆ¸ä½™é¢"] > 0].groupby("è¯åˆ¸ä»£ç ")["å¹´ä»½"].min().to_dict()
df_merged["Post"] = df_merged.apply(
    lambda x: 1 if (x["Treat"] == 1 and x["å¹´ä»½"] >= first_year.get(x["è¯åˆ¸ä»£ç "], 9999)) else 0,
    axis=1
)

# æ ¸å¿ƒäº¤äº’é¡¹
df_merged["DID"] = df_merged["Treat"] * df_merged["Post"]

# è¡Œä¸šç«äº‰åˆ†ç»„
year_median = df_merged.groupby("å¹´ä»½")["HHI_A"].median().to_dict()
df_merged["è¡Œä¸šç«äº‰åˆ†ç»„"] = df_merged.apply(
    lambda x: "é«˜ç«äº‰ç»„" if x["HHI_A"] < year_median[x["å¹´ä»½"]] else "ä½ç«äº‰ç»„",
    axis=1
)

# ä¿å­˜å®è¯åˆ†æåŸºç¡€åº“
df_merged.to_csv(f"{OUTPUT_PATH}å®è¯åˆ†æåŸºç¡€åº“2.csv", encoding=ENCODING, index=False)
print(f"å®è¯åˆ†æåŸºç¡€åº“æ•°æ®é‡: {df_merged.shape}")

# ====================== æ­¥éª¤6ï¼šæµ‹ç®—èµ„æœ¬ç»“æ„è°ƒæ•´é€Ÿåº¦ ======================
print("\n" + "="*60)
print("æ­¥éª¤6ï¼šæµ‹ç®—èµ„æœ¬ç»“æ„è°ƒæ•´é€Ÿåº¦")
print("="*60)

# å‡†å¤‡å›å½’æ•°æ®
required_cols = ["è¯åˆ¸ä»£ç ", "å¹´ä»½", "å®é™…è´Ÿå€ºç‡", "ä¼ä¸šè§„æ¨¡", "ç›ˆåˆ©èƒ½åŠ›", "æˆé•¿æ€§",
                "ç¬¬ä¸€å¤§è‚¡ä¸œæŒè‚¡æ¯”ç‡(%)", "èµ„äº§æ‹…ä¿ä»·å€¼", "ç‹¬ç«‹è‘£äº‹å æ¯”"]
df_reg = df_merged[required_cols].dropna()

# è½¬æ¢æ•°å€¼ç±»å‹
for col in required_cols[2:]:
    df_reg[col] = pd.to_numeric(df_reg[col], errors="coerce")
df_reg = df_reg.dropna()

# è®¡ç®—ç›®æ ‡è´Ÿå€ºç‡ï¼ˆæŒ‰å…¬å¸ä¸ªä½“å›å½’ï¼‰
results = []
for code in df_reg["è¯åˆ¸ä»£ç "].unique():
    company_data = df_reg[df_reg["è¯åˆ¸ä»£ç "] == code].copy()
    if len(company_data) < 3:
        continue
    
    X = company_data[["ä¼ä¸šè§„æ¨¡", "ç›ˆåˆ©èƒ½åŠ›", "æˆé•¿æ€§", "ç¬¬ä¸€å¤§è‚¡ä¸œæŒè‚¡æ¯”ç‡(%)",
                    "èµ„äº§æ‹…ä¿ä»·å€¼", "ç‹¬ç«‹è‘£äº‹å æ¯”"]].values
    y = company_data["å®é™…è´Ÿå€ºç‡"].values
    
    try:
        beta = linear_regression(X, y)
        X_with_const = np.column_stack([np.ones(len(X)), X])
        company_data["ç›®æ ‡è´Ÿå€ºç‡"] = X_with_const @ beta
        results.append(company_data)
    except:
        continue

df_with_target = pd.concat(results)

# è®¡ç®—è°ƒæ•´çŠ¶æ€æŒ‡æ ‡
df_with_target = df_with_target.sort_values(["è¯åˆ¸ä»£ç ", "å¹´ä»½"])
df_with_target["ä¸ŠæœŸå®é™…è´Ÿå€ºç‡"] = df_with_target.groupby("è¯åˆ¸ä»£ç ")["å®é™…è´Ÿå€ºç‡"].shift(1)
df_with_target["ä¸ŠæœŸç›®æ ‡è´Ÿå€ºç‡"] = df_with_target.groupby("è¯åˆ¸ä»£ç ")["ç›®æ ‡è´Ÿå€ºç‡"].shift(1)
df_with_target["è´Ÿå€ºç‡å˜åŠ¨"] = df_with_target["å®é™…è´Ÿå€ºç‡"] - df_with_target["ä¸ŠæœŸå®é™…è´Ÿå€ºç‡"]
df_with_target["åç¦»ç¨‹åº¦"] = df_with_target["ä¸ŠæœŸç›®æ ‡è´Ÿå€ºç‡"] - df_with_target["ä¸ŠæœŸå®é™…è´Ÿå€ºç‡"]

# å‰”é™¤ç©ºå€¼
df_reg_final = df_with_target.dropna(subset=["è´Ÿå€ºç‡å˜åŠ¨", "åç¦»ç¨‹åº¦"])

# å›å½’æµ‹ç®—è°ƒæ•´é€Ÿåº¦
X = df_reg_final["åç¦»ç¨‹åº¦"].values.reshape(-1,1)
y = df_reg_final["è´Ÿå€ºç‡å˜åŠ¨"].values
beta = linear_regression(X, y)

print(f"\nèµ„æœ¬ç»“æ„è°ƒæ•´é€Ÿåº¦æµ‹ç®—ç»“æœ:")
print(f"è°ƒæ•´é€Ÿåº¦ç³»æ•°: {beta[1]:.4f}")
print(f"æˆªè·é¡¹: {beta[0]:.4f}")

# ä¿å­˜æœ€ç»ˆå›å½’æ•°æ®
df_reg_final.to_csv(f"{OUTPUT_PATH}æœ€ç»ˆå›å½’æ•°æ®.csv", encoding=ENCODING, index=False)
print(f"\næœ€ç»ˆå›å½’æ•°æ®é‡: {df_reg_final.shape}")
print("="*60)
print("æ‰€æœ‰æµç¨‹æ‰§è¡Œå®Œæˆï¼")
